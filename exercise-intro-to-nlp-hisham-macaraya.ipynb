{"cells":[{"cell_type":"markdown","metadata":{},"source":["**This notebook is an exercise in the [Natural Language Processing](https://www.kaggle.com/learn/natural-language-processing) course.  You can reference the tutorial at [this link](https://www.kaggle.com/matleonard/intro-to-nlp).**\n","\n","---\n"]},{"cell_type":"markdown","metadata":{},"source":["# Basic Text Processing with Spacy\n","    \n","You're a consultant for [DelFalco's Italian Restaurant](https://defalcosdeli.com/index.html).\n","The owner asked you to identify whether there are any foods on their menu that diners find disappointing. \n","\n","<img src=\"https://i.imgur.com/8DZunAQ.jpg\" alt=\"Meatball Sub\" width=\"250\"/>\n","\n","Before getting started, run the following cell to set up code checking."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:33.980963Z","iopub.status.busy":"2024-08-29T01:12:33.980497Z","iopub.status.idle":"2024-08-29T01:12:33.988516Z","shell.execute_reply":"2024-08-29T01:12:33.987243Z","shell.execute_reply.started":"2024-08-29T01:12:33.980925Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'learntools.core'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Set up code checking\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlearntools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m binder\n\u001b[0;32m      5\u001b[0m binder\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlearntools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mex1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'learntools.core'"]}],"source":["import pandas as pd\n","\n","# Set up code checking\n","from learntools.core import binder\n","binder.bind(globals())\n","from learntools.nlp.ex1 import *\n","print('Setup Complete')"]},{"cell_type":"markdown","metadata":{},"source":["The business owner suggested you use diner reviews from the Yelp website to determine which dishes people liked and disliked. You pulled the data from Yelp. Before you get to analysis, run the code cell below for a quick look at the data you have to work with."]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:33.991658Z","iopub.status.busy":"2024-08-29T01:12:33.991073Z","iopub.status.idle":"2024-08-29T01:12:34.047282Z","shell.execute_reply":"2024-08-29T01:12:34.046092Z","shell.execute_reply.started":"2024-08-29T01:12:33.991602Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"File ../input/nlp-course/restaurant.json does not exist","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load in the data from JSON file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../input/nlp-course/restaurant.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n","File \u001b[1;32mc:\\Users\\hisha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\json\\_json.py:791\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    789\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n","File \u001b[1;32mc:\\Users\\hisha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\json\\_json.py:904\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n","File \u001b[1;32mc:\\Users\\hisha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\json\\_json.py:960\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    952\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[0;32m    959\u001b[0m ):\n\u001b[1;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal json to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    967\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    968\u001b[0m     )\n","\u001b[1;31mFileNotFoundError\u001b[0m: File ../input/nlp-course/restaurant.json does not exist"]}],"source":["# Load in the data from JSON file\n","data = pd.read_json('../input/nlp-course/restaurant.json')\n","data.head()"]},{"cell_type":"markdown","metadata":{},"source":["The owner also gave you this list of menu items and common alternate spellings."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:34.049944Z","iopub.status.busy":"2024-08-29T01:12:34.049513Z","iopub.status.idle":"2024-08-29T01:12:34.057607Z","shell.execute_reply":"2024-08-29T01:12:34.056298Z","shell.execute_reply.started":"2024-08-29T01:12:34.049903Z"},"trusted":true},"outputs":[],"source":["menu = [\"Cheese Steak\", \"Cheesesteak\", \"Steak and Cheese\", \"Italian Combo\", \"Tiramisu\", \"Cannoli\",\n","        \"Chicken Salad\", \"Chicken Spinach Salad\", \"Meatball\", \"Pizza\", \"Pizzas\", \"Spaghetti\",\n","        \"Bruchetta\", \"Eggplant\", \"Italian Beef\", \"Purista\", \"Pasta\", \"Calzones\",  \"Calzone\",\n","        \"Italian Sausage\", \"Chicken Cutlet\", \"Chicken Parm\", \"Chicken Parmesan\", \"Gnocchi\",\n","        \"Chicken Pesto\", \"Turkey Sandwich\", \"Turkey Breast\", \"Ziti\", \"Portobello\", \"Reuben\",\n","        \"Mozzarella Caprese\",  \"Corned Beef\", \"Garlic Bread\", \"Pastrami\", \"Roast Beef\",\n","        \"Tuna Salad\", \"Lasagna\", \"Artichoke Salad\", \"Fettuccini Alfredo\", \"Chicken Parmigiana\",\n","        \"Grilled Veggie\", \"Grilled Veggies\", \"Grilled Vegetable\", \"Mac and Cheese\", \"Macaroni\",  \n","         \"Prosciutto\", \"Salami\"]"]},{"cell_type":"markdown","metadata":{},"source":["# Step 1: Plan Your Analysis"]},{"cell_type":"markdown","metadata":{},"source":["Given the data from Yelp and the list of menu items, do you have any ideas for how you could find which menu items have disappointed diners?\n","\n","Think about your answer. Then run the cell below to see one approach."]},{"cell_type":"markdown","metadata":{},"source":["### **My answer**\n","\n","To identify which menu items have disappointed diners using Yelp data, you can start by performing sentiment analysis on the reviews. This involves using natural language processing (NLP) techniques to classify the sentiment of each review as positive, negative, or neutral. Tools like SpaCy can be helpful for this task. Once you have the sentiment scores, you can aggregate the results for each menu item to determine the overall sentiment. Additionally, you can look for specific keywords or phrases that indicate dissatisfaction, such as “disappointed,” “bad,” or “not good.” By combining these methods, you can create a list of menu items that have received the most negative feedback from diners."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:34.060365Z","iopub.status.busy":"2024-08-29T01:12:34.059934Z","iopub.status.idle":"2024-08-29T01:12:34.074132Z","shell.execute_reply":"2024-08-29T01:12:34.072938Z","shell.execute_reply.started":"2024-08-29T01:12:34.060307Z"},"trusted":true},"outputs":[],"source":["# Check your answer (Run this code cell to receive credit!)\n","#q_1.solution()"]},{"cell_type":"markdown","metadata":{},"source":["# Step 2: Find items in one review\n","\n","You'll pursue this plan of calculating average scores of the reviews mentioning each menu item.\n","\n","As a first step, you'll write code to extract the foods mentioned in a single review.\n","\n","Since menu items are multiple tokens long, you'll use `PhraseMatcher` which can match series of tokens.\n","\n","Fill in the `____` values below to get a list of items matching a single menu item."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:34.077893Z","iopub.status.busy":"2024-08-29T01:12:34.077355Z","iopub.status.idle":"2024-08-29T01:12:34.402737Z","shell.execute_reply":"2024-08-29T01:12:34.401575Z","shell.execute_reply.started":"2024-08-29T01:12:34.077836Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'spacy'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#This is my answer:\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PhraseMatcher\n\u001b[0;32m      6\u001b[0m index_of_review_to_test_on \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m14\u001b[39m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"]}],"source":["#This is my answer:\n","\n","import spacy\n","from spacy.matcher import PhraseMatcher\n","\n","index_of_review_to_test_on = 14\n","text_to_test_on = data.text.iloc[index_of_review_to_test_on]\n","\n","# Load the SpaCy model\n","nlp = spacy.blank('en')\n","\n","# Create the tokenized version of text_to_test_on\n","review_doc = nlp(text_to_test_on)\n","\n","# Create the PhraseMatcher object. The tokenizer is the first argument. Use attr = 'LOWER' to make consistent capitalization\n","matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n","\n","# Create a list of tokens for each item in the menu\n","menu_tokens_list = [nlp(item)  for item in menu]\n","\n","# Add the item patterns to the matcher. \n","# Look at https://spacy.io/api/phrasematcher#add in the docs for help with this step\n","# Then uncomment the lines below \n","\n","\n","matcher.add(\"MENU\", menu_tokens_list)            # Just a name for the set of rules we're matching to\n","\n","# Find matches in the review_doc\n","matches = matcher(review_doc)\n","\n","# Uncomment to check your work\n","q_2.check()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:34.404599Z","iopub.status.busy":"2024-08-29T01:12:34.404218Z","iopub.status.idle":"2024-08-29T01:12:34.409843Z","shell.execute_reply":"2024-08-29T01:12:34.408450Z","shell.execute_reply.started":"2024-08-29T01:12:34.404558Z"},"trusted":true},"outputs":[],"source":["# Lines below will give you a hint or solution code\n","#q_2.hint()\n","#q_2.solution()"]},{"cell_type":"markdown","metadata":{},"source":["After implementing the above cell, uncomment the following cell to print the matches."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:34.412094Z","iopub.status.busy":"2024-08-29T01:12:34.411513Z","iopub.status.idle":"2024-08-29T01:12:34.423109Z","shell.execute_reply":"2024-08-29T01:12:34.421795Z","shell.execute_reply.started":"2024-08-29T01:12:34.412039Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Token number 2: Purista\n","Token number 16: prosciutto\n","Token number 58: meatball\n"]}],"source":["for match in matches:\n","    print(f\"Token number {match[1]}: {review_doc[match[1]:match[2]]}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Step 3: Matching on the whole dataset\n","\n","Now run this matcher over the whole dataset and collect ratings for each menu item. Each review has a rating, `review.stars`. For each item that appears in the review text (`review.text`), append the review's rating to a list of ratings for that item. The lists are kept in a dictionary `item_ratings`.\n","\n","To get the matched phrases, you can reference the `PhraseMatcher` documentation for the structure of each match object:\n","\n",">A list of `(match_id, start, end)` tuples, describing the matches. A match tuple describes a span `doc[start:end]`. The `match_id` is the ID of the added match pattern."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:34.425089Z","iopub.status.busy":"2024-08-29T01:12:34.424657Z","iopub.status.idle":"2024-08-29T01:12:35.855893Z","shell.execute_reply":"2024-08-29T01:12:35.854596Z","shell.execute_reply.started":"2024-08-29T01:12:34.425049Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'data' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# item_ratings is a dictionary of lists. If a key doesn't exist in item_ratings,\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# the key is added with an empty list as the value.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m item_ratings \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, review \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     10\u001b[0m     doc \u001b[38;5;241m=\u001b[39m nlp(review\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Using the matcher from the previous exercise\u001b[39;00m\n","\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"]}],"source":["#This is my answer:\n","\n","from collections import defaultdict\n","\n","# item_ratings is a dictionary of lists. If a key doesn't exist in item_ratings,\n","# the key is added with an empty list as the value.\n","item_ratings = defaultdict(list)\n","\n","for idx, review in data.iterrows():\n","    doc = nlp(review.text)\n","    # Using the matcher from the previous exercise\n","    matches = matcher(doc)\n","    \n","    # Create a set of the items found in the review text\n","    found_items = {doc[start:end].text.lower() for match_id, start, end in matches}\n","    \n","    # Update item_ratings with rating for each item in found_items\n","    # Transform the item strings to lowercase to make it case insensitive\n","    for item in found_items:\n","        item_ratings[item].append(review.stars)\n","\n","q_3.check()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:35.857822Z","iopub.status.busy":"2024-08-29T01:12:35.857413Z","iopub.status.idle":"2024-08-29T01:12:35.862935Z","shell.execute_reply":"2024-08-29T01:12:35.861616Z","shell.execute_reply.started":"2024-08-29T01:12:35.857779Z"},"trusted":true},"outputs":[],"source":["# Lines below will give you a hint or solution code\n","#q_3.hint()\n","#q_3.solution()"]},{"cell_type":"markdown","metadata":{},"source":["# Step 4: What's the worst reviewed item?\n","\n","Using these item ratings, find the menu item with the worst average rating."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:35.864966Z","iopub.status.busy":"2024-08-29T01:12:35.864487Z","iopub.status.idle":"2024-08-29T01:12:35.882592Z","shell.execute_reply":"2024-08-29T01:12:35.881388Z","shell.execute_reply.started":"2024-08-29T01:12:35.864920Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'item_ratings' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Calculate the mean ratings for each menu item as a dictionary\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m mean_ratings \u001b[38;5;241m=\u001b[39m {item: np\u001b[38;5;241m.\u001b[39mmean(ratings) \u001b[38;5;28;01mfor\u001b[39;00m item, ratings \u001b[38;5;129;01min\u001b[39;00m \u001b[43mitem_ratings\u001b[49m\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Find the worst item, and write it as a string in worst_item. This can be multiple lines of code if you want.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m worst_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(mean_ratings, key\u001b[38;5;241m=\u001b[39mmean_ratings\u001b[38;5;241m.\u001b[39mget)\n","\u001b[1;31mNameError\u001b[0m: name 'item_ratings' is not defined"]}],"source":["#This is my answer\n","\n","import numpy as np\n","\n","# Calculate the mean ratings for each menu item as a dictionary\n","mean_ratings = {item: np.mean(ratings) for item, ratings in item_ratings.items()}\n","\n","# Find the worst item, and write it as a string in worst_item. This can be multiple lines of code if you want.\n","worst_item = min(mean_ratings, key=mean_ratings.get)\n","\n","q_4.check() "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:35.887901Z","iopub.status.busy":"2024-08-29T01:12:35.887281Z","iopub.status.idle":"2024-08-29T01:12:35.897487Z","shell.execute_reply":"2024-08-29T01:12:35.896205Z","shell.execute_reply.started":"2024-08-29T01:12:35.887849Z"},"trusted":true},"outputs":[],"source":["# Lines below will give you a hint or solution code\n","#q_4.hint()\n","#q_4.solution()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:35.899627Z","iopub.status.busy":"2024-08-29T01:12:35.899085Z","iopub.status.idle":"2024-08-29T01:12:35.910435Z","shell.execute_reply":"2024-08-29T01:12:35.909293Z","shell.execute_reply.started":"2024-08-29T01:12:35.899572Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["chicken cutlet\n","3.4\n"]}],"source":["# After implementing the above cell, uncomment and run this to print \n","# out the worst item, along with its average rating. \n","\n","print(worst_item)\n","print(mean_ratings[worst_item])"]},{"cell_type":"markdown","metadata":{},"source":["### **My Answer**\n","\n","The worst reviewed item is the Chicken Cutlet with 3.4 average rating."]},{"cell_type":"markdown","metadata":{},"source":["# Step 5: Are counts important here?\n","\n","Similar to the mean ratings, you can calculate the number of reviews for each item."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:35.912618Z","iopub.status.busy":"2024-08-29T01:12:35.912080Z","iopub.status.idle":"2024-08-29T01:12:35.925467Z","shell.execute_reply":"2024-08-29T01:12:35.924201Z","shell.execute_reply.started":"2024-08-29T01:12:35.912564Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                    pizza  265\n","                    pasta  206\n","                 meatball  128\n","              cheesesteak   97\n","             cheese steak   76\n","                  cannoli   72\n","                  calzone   72\n","                 eggplant   69\n","                  purista   63\n","                  lasagna   59\n","          italian sausage   53\n","               prosciutto   50\n","             chicken parm   50\n","             garlic bread   39\n","                  gnocchi   37\n","                spaghetti   36\n","                 calzones   35\n","                   pizzas   32\n","                   salami   28\n","            chicken pesto   27\n","             italian beef   25\n","            italian combo   21\n","                 tiramisu   21\n","                     ziti   21\n","         chicken parmesan   19\n","       chicken parmigiana   17\n","               portobello   14\n","           mac and cheese   11\n","           chicken cutlet   10\n","         steak and cheese    9\n","                 pastrami    9\n","               roast beef    7\n","       fettuccini alfredo    6\n","           grilled veggie    6\n","               tuna salad    5\n","          turkey sandwich    5\n","          artichoke salad    5\n","                 macaroni    5\n","            chicken salad    5\n","                   reuben    4\n","    chicken spinach salad    2\n","              corned beef    2\n","            turkey breast    1\n"]}],"source":["counts = {item: len(ratings) for item, ratings in item_ratings.items()}\n","\n","item_counts = sorted(counts, key=counts.get, reverse=True)\n","for item in item_counts:\n","    print(f\"{item:>25}{counts[item]:>5}\")"]},{"cell_type":"markdown","metadata":{},"source":["Here is code to print the 10 best and 10 worst rated items. Look at the results, and decide whether you think it's important to consider the number of reviews when interpreting scores of which items are best and worst."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:35.927421Z","iopub.status.busy":"2024-08-29T01:12:35.926986Z","iopub.status.idle":"2024-08-29T01:12:35.938408Z","shell.execute_reply":"2024-08-29T01:12:35.937278Z","shell.execute_reply.started":"2024-08-29T01:12:35.927372Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Worst rated menu items:\n","chicken cutlet       Ave rating: 3.40 \tcount: 10\n","turkey sandwich      Ave rating: 3.80 \tcount: 5\n","spaghetti            Ave rating: 3.89 \tcount: 36\n","italian beef         Ave rating: 3.92 \tcount: 25\n","tuna salad           Ave rating: 4.00 \tcount: 5\n","macaroni             Ave rating: 4.00 \tcount: 5\n","italian combo        Ave rating: 4.05 \tcount: 21\n","garlic bread         Ave rating: 4.13 \tcount: 39\n","roast beef           Ave rating: 4.14 \tcount: 7\n","eggplant             Ave rating: 4.16 \tcount: 69\n","\n","\n","Best rated menu items:\n","chicken pesto        Ave rating: 4.56 \tcount: 27\n","chicken salad        Ave rating: 4.60 \tcount: 5\n","purista              Ave rating: 4.67 \tcount: 63\n","prosciutto           Ave rating: 4.68 \tcount: 50\n","reuben               Ave rating: 4.75 \tcount: 4\n","steak and cheese     Ave rating: 4.89 \tcount: 9\n","artichoke salad      Ave rating: 5.00 \tcount: 5\n","fettuccini alfredo   Ave rating: 5.00 \tcount: 6\n","turkey breast        Ave rating: 5.00 \tcount: 1\n","corned beef          Ave rating: 5.00 \tcount: 2\n"]}],"source":["sorted_ratings = sorted(mean_ratings, key=mean_ratings.get)\n","\n","print(\"Worst rated menu items:\")\n","for item in sorted_ratings[:10]:\n","    print(f\"{item:20} Ave rating: {mean_ratings[item]:.2f} \\tcount: {counts[item]}\")\n","    \n","print(\"\\n\\nBest rated menu items:\")\n","for item in sorted_ratings[-10:]:\n","    print(f\"{item:20} Ave rating: {mean_ratings[item]:.2f} \\tcount: {counts[item]}\")"]},{"cell_type":"markdown","metadata":{},"source":["Run the following line after you've decided your answer."]},{"cell_type":"markdown","metadata":{},"source":["### **My Answer**\n","\n","Yes, counts can be important when interpreting the scores of which items are best and worst. Items with very few reviews might have skewed ratings due to the small sample size. For example, an item with only one or two reviews might have an unusually high or low rating that doesn't accurately reflect its overall quality. Conversely, items with many reviews are likely to have more reliable average ratings because the larger sample size reduces the impact of any single review.\n","\n","To ensure a more accurate interpretation, it's helpful to consider both the average rating and the number of reviews. Items with high average ratings and a large number of reviews are generally more reliable indicators of quality. Conversely, items with low average ratings and a large number of reviews are more likely to be genuinely poor.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T01:12:35.941143Z","iopub.status.busy":"2024-08-29T01:12:35.939938Z","iopub.status.idle":"2024-08-29T01:12:35.950033Z","shell.execute_reply":"2024-08-29T01:12:35.948913Z","shell.execute_reply.started":"2024-08-29T01:12:35.941061Z"},"trusted":true},"outputs":[],"source":["# Check your answer (Run this code cell to receive credit!)\n","#q_5.solution()"]},{"cell_type":"markdown","metadata":{},"source":["# Keep Going\n","\n","Now that you are ready to combine your NLP skills with your ML skills, **[see how it's done](https://www.kaggle.com/matleonard/text-classification)**."]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","\n","\n","\n","*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/natural-language-processing/discussion) to chat with other learners.*"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":348259,"sourceId":695175,"sourceType":"datasetVersion"},{"datasetId":362178,"sourceId":763778,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
